{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Roberta_Text_Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9c4bd3848ce542b79a89a7e8580b5257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_84e33bd114de448e82f6de05bc590cd3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1824566b5cbb48cf8f7cc54693f371e1",
              "IPY_MODEL_b4edd55640624c7d814a2ab3fa45cc9f"
            ]
          }
        },
        "84e33bd114de448e82f6de05bc590cd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1824566b5cbb48cf8f7cc54693f371e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ad8b42fdf90d4c3698d45d22e92cc5d5",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e30cfca6a98454e8eeb02d09132d0b2"
          }
        },
        "b4edd55640624c7d814a2ab3fa45cc9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_06f0c13be8384ac7ab304c2081f77fef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [09:26&lt;00:00, 188.92s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a41f59d7cf56418680a20d928a176dcc"
          }
        },
        "ad8b42fdf90d4c3698d45d22e92cc5d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e30cfca6a98454e8eeb02d09132d0b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06f0c13be8384ac7ab304c2081f77fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a41f59d7cf56418680a20d928a176dcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTfJ8viaFX0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Exercise - 1: I have provided sparse comments. Please provide detailed comments using what you have understood about Transformers. Especially\n",
        "the \"Roberta\" framework in particular.\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oai8ILeDG01_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### CRITICAL - ENABLE GPU (Runtime > Change Runtime type > GPU)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHeQ7XzzUoa_",
        "colab_type": "code",
        "outputId": "0c9bfa1c-59ea-41ee-92ea-eb51fcad9e16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json, re\n",
        "from tqdm import tqdm_notebook\n",
        "from uuid import uuid4\n",
        "\n",
        "## Torch Modules\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "## Mount Drive into Colab\n",
        "'''\n",
        "We are dealing here with a massive dataset. We need to mount the google drive.\n",
        "Once you run the code below follow google's prompts to sucessfully mount the drive\n",
        "\n",
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Zu4e2qMU-p9",
        "colab_type": "code",
        "outputId": "3501466b-65a3-456d-f9ed-63629164c326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "'''\n",
        "Install this\n",
        "'''\n",
        "\n",
        "!pip install pytorch-transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
            "\r\u001b[K     |█▉                              | 10kB 13.7MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92kB 12.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 102kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 133kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 174kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 9.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.18.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.38.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.12.31)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 54.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.4.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 61.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.8)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.31 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.15.31)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.9.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->pytorch-transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->pytorch-transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=ee8548386c8c55b3ae19a30669790754df4c742d9d21789c1c7ddd16beeb28ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, pytorch-transformers\n",
            "Successfully installed pytorch-transformers-1.2.0 sacremoses-0.0.38 sentencepiece-0.1.85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzl8c6LoUt4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## PyTorch Transformer\n",
        "from pytorch_transformers import RobertaModel, RobertaTokenizer\n",
        "from pytorch_transformers import RobertaForSequenceClassification, RobertaConfig"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTQIXk88UuB0",
        "colab_type": "code",
        "outputId": "2bf51826-0e30-4c8a-d34a-4340d6e0b350",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## Make Sure Cuda is Available\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFRQJMjKUuEU",
        "colab_type": "code",
        "outputId": "7c4f278a-1400-4063-a6ce-d6ae7e6e4196",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "'''\n",
        "Important Step - Make sure you upload the data file to the exact location below. If you uploaded correctlt, the follwoing command will run\n",
        "'''\n",
        "\n",
        "!ls drive/'My Drive'/2017-06-custom-intent-engines"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AddToPlaylist\tGetWeather  RateBook   SearchCreativeWork\n",
            "BookRestaurant\tPlayMusic   README.md  SearchScreeningEvent\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMpF3sYJX-z3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Create the Dataset Path\n",
        "'''\n",
        "\n",
        "dataset_path = \"drive/My Drive/2017-06-custom-intent-engines/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxWTXqWMUuGj",
        "colab_type": "code",
        "outputId": "82453582-972b-48b3-b123-78c87deab96c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "'''\n",
        "Code to Prep Data and see how it looks\n",
        "'''\n",
        "\n",
        "\n",
        "dataset = pd.DataFrame(columns = ['utterance', 'label'])\n",
        "for intent in ['AddToPlaylist', 'BookRestaurant', 'GetWeather', 'PlayMusic', 'RateBook', 'SearchCreativeWork',\n",
        "               'SearchScreeningEvent']:\n",
        "    with open(dataset_path + intent + \"/train_\" + intent + \".json\",\n",
        "              encoding='cp1251') as data_file:\n",
        "        data = json.load(data_file)\n",
        "    print(\"Class: {}, # utterances: {}\".format(intent,len(data[intent])))\n",
        "    texts = []\n",
        "    for i in range(len(data[intent])):\n",
        "        text = ''\n",
        "        for j in range(len(data[intent][i]['data'])):\n",
        "            text += data[intent][i]['data'][j]['text']\n",
        "        dataset = dataset.append({'utterance': text, 'label': intent}, ignore_index=True)\n",
        "dataset.tail()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: AddToPlaylist, # utterances: 300\n",
            "Class: BookRestaurant, # utterances: 300\n",
            "Class: GetWeather, # utterances: 300\n",
            "Class: PlayMusic, # utterances: 300\n",
            "Class: RateBook, # utterances: 300\n",
            "Class: SearchCreativeWork, # utterances: 300\n",
            "Class: SearchScreeningEvent, # utterances: 300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>utterance</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2095</th>\n",
              "      <td>Is Across the Line playing at the closest movi...</td>\n",
              "      <td>SearchScreeningEvent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2096</th>\n",
              "      <td>Which animated movies are playing in the neigh...</td>\n",
              "      <td>SearchScreeningEvent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2097</th>\n",
              "      <td>Where is They Always Return at Dawn playing</td>\n",
              "      <td>SearchScreeningEvent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2098</th>\n",
              "      <td>What is the movie schedule in the neighborhood</td>\n",
              "      <td>SearchScreeningEvent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2099</th>\n",
              "      <td>Tell me when Howling II: Your Sister Is a Were...</td>\n",
              "      <td>SearchScreeningEvent</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              utterance                 label\n",
              "2095  Is Across the Line playing at the closest movi...  SearchScreeningEvent\n",
              "2096  Which animated movies are playing in the neigh...  SearchScreeningEvent\n",
              "2097        Where is They Always Return at Dawn playing  SearchScreeningEvent\n",
              "2098     What is the movie schedule in the neighborhood  SearchScreeningEvent\n",
              "2099  Tell me when Howling II: Your Sister Is a Were...  SearchScreeningEvent"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k72gKNxJUuNO",
        "colab_type": "code",
        "outputId": "917a8d7f-17cb-4baa-fb70-703a50bd713b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "'''\n",
        "Assigning an Index to each intent. We will use this later\n",
        "'''\n",
        "\n",
        "label_to_ix = {}\n",
        "for label in dataset.label:\n",
        "    for word in label.split():\n",
        "        if word not in label_to_ix:\n",
        "            label_to_ix[word]=len(label_to_ix)\n",
        "label_to_ix"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AddToPlaylist': 0,\n",
              " 'BookRestaurant': 1,\n",
              " 'GetWeather': 2,\n",
              " 'PlayMusic': 3,\n",
              " 'RateBook': 4,\n",
              " 'SearchCreativeWork': 5,\n",
              " 'SearchScreeningEvent': 6}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsKYHHUNYxwp",
        "colab_type": "code",
        "outputId": "7f86a10a-7dcd-48eb-d979-7c89caab1f46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "'''\n",
        "Loading Configurations\n",
        "'''\n",
        "\n",
        "config = RobertaConfig.from_pretrained('roberta-base')\n",
        "config.num_labels = len(list(label_to_ix.values()))\n",
        "config"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\n",
              "  \"architectures\": [\n",
              "    \"RobertaForMaskedLM\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"finetuning_task\": null,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"layer_norm_eps\": 1e-05,\n",
              "  \"max_position_embeddings\": 514,\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"num_labels\": 7,\n",
              "  \"output_attentions\": false,\n",
              "  \"output_hidden_states\": false,\n",
              "  \"pruned_heads\": {},\n",
              "  \"torchscript\": false,\n",
              "  \"type_vocab_size\": 1,\n",
              "  \"vocab_size\": 50265\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWLzatueYx59",
        "colab_type": "code",
        "outputId": "ab82b2e7-5136-4c66-8cc4-bb293242b24e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "'''\n",
        "Loading Pretrained tokenizer and instantiating the model from settings in config\n",
        "'''\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = RobertaForSequenceClassification(config)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 898823/898823 [00:00<00:00, 2100798.15B/s]\n",
            "100%|██████████| 456318/456318 [00:00<00:00, 1330732.33B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbS9Q6qIYx8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Some important Feature Engineering\n",
        "'''\n",
        "\n",
        "\n",
        "def prepare_features(seq_1, max_seq_length = 300, \n",
        "             zero_pad = False, include_CLS_token = True, include_SEP_token = True):\n",
        "    ## Tokenzine Input\n",
        "    tokens_a = tokenizer.tokenize(seq_1)\n",
        "\n",
        "    ## Truncate\n",
        "    if len(tokens_a) > max_seq_length - 2:\n",
        "        tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
        "    ## Initialize Tokens\n",
        "    tokens = []\n",
        "    if include_CLS_token:\n",
        "        tokens.append(tokenizer.cls_token)\n",
        "    ## Add Tokens and separators\n",
        "    for token in tokens_a:\n",
        "        tokens.append(token)\n",
        "\n",
        "    if include_SEP_token:\n",
        "        tokens.append(tokenizer.sep_token)\n",
        "\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    ## Input Mask \n",
        "    input_mask = [1] * len(input_ids)\n",
        "    ## Zero-pad sequence lenght\n",
        "    if zero_pad:\n",
        "        while len(input_ids) < max_seq_length:\n",
        "            input_ids.append(0)\n",
        "            input_mask.append(0)\n",
        "    return torch.tensor(input_ids).unsqueeze(0), input_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G344YtsYx-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Wrapping the labels and data together in a Class.\n",
        "'''\n",
        "\n",
        "class Intents(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        utterance = self.data.utterance[index]\n",
        "        label = self.data.label[index]\n",
        "        X, _  = prepare_features(utterance)\n",
        "        y = label_to_ix[self.data.label[index]]\n",
        "        return X, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnETiekbYyA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Test Train Split\n",
        "'''\n",
        "\n",
        "train_size = 0.8\n",
        "train_dataset=dataset.sample(frac=train_size,random_state=200).reset_index(drop=True)\n",
        "test_dataset=dataset.drop(train_dataset.index).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqlYN6ptYyDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Train /Test sets ready\n",
        "'''\n",
        "\n",
        "training_set = Intents(train_dataset)\n",
        "testing_set = Intents(test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sleUPc7BYyFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6pSUA-cYyH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "params = {'batch_size': 1,\n",
        "          'shuffle': True,\n",
        "          'drop_last': False,\n",
        "          'num_workers': 1}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79YrjZIDYyJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Pull data into dataloader for efficiency\n",
        "'''\n",
        "training_loader = DataLoader(training_set, **params)\n",
        "testing_loader = DataLoader(testing_set, **params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bU1jTfyZN6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Instantiate the Loss\n",
        "'''\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "learning_rate = 1e-05\n",
        "optimizer = optim.Adam(params =  model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVTDKDKaZN9K",
        "colab_type": "code",
        "outputId": "00e65a84-cb6e-430d-eeff-dfb73d3c5ccb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## Test Forward Pass\n",
        "inp = training_set.__getitem__(0)[0].cuda()\n",
        "output = model(inp)[0]\n",
        "print(output.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uzIIqQbZN_H",
        "colab_type": "code",
        "outputId": "48fe03ee-f80d-40ad-8da7-25d5f7d5b0c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9c4bd3848ce542b79a89a7e8580b5257",
            "84e33bd114de448e82f6de05bc590cd3",
            "1824566b5cbb48cf8f7cc54693f371e1",
            "b4edd55640624c7d814a2ab3fa45cc9f",
            "ad8b42fdf90d4c3698d45d22e92cc5d5",
            "8e30cfca6a98454e8eeb02d09132d0b2",
            "06f0c13be8384ac7ab304c2081f77fef",
            "a41f59d7cf56418680a20d928a176dcc"
          ]
        }
      },
      "source": [
        "'''\n",
        "Actually train the model with train data\n",
        "'''\n",
        "\n",
        "\n",
        "max_epochs = 3\n",
        "model = model.train()\n",
        "for epoch in tqdm_notebook(range(max_epochs)):\n",
        "    print(\"EPOCH -- {}\".format(epoch))\n",
        "    for i, (sent, label) in enumerate(training_loader):\n",
        "        optimizer.zero_grad()\n",
        "        sent = sent.squeeze(0)\n",
        "        if torch.cuda.is_available():\n",
        "          sent = sent.cuda()\n",
        "          label = label.cuda()\n",
        "        output = model.forward(sent)[0]\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        \n",
        "        loss = loss_function(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if i%100 == 0:\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for sent, label in testing_loader:\n",
        "                sent = sent.squeeze(0)\n",
        "                if torch.cuda.is_available():\n",
        "                  sent = sent.cuda()\n",
        "                  label = label.cuda()\n",
        "                output = model.forward(sent)[0]\n",
        "                _, predicted = torch.max(output.data, 1)\n",
        "                total += label.size(0)\n",
        "                correct += (predicted.cpu() == label.cpu()).sum()\n",
        "            accuracy = 100.00 * correct.numpy() / total\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}%'.format(i, loss.item(), accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c4bd3848ce542b79a89a7e8580b5257",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH -- 0\n",
            "Iteration: 0. Loss: 1.8607558012008667. Accuracy: 1.1904761904761905%\n",
            "Iteration: 100. Loss: 1.6472851037979126. Accuracy: 2.380952380952381%\n",
            "Iteration: 200. Loss: 1.9056799411773682. Accuracy: 0.23809523809523808%\n",
            "Iteration: 300. Loss: 1.5030757188796997. Accuracy: 0.23809523809523808%\n",
            "Iteration: 400. Loss: 1.7159450054168701. Accuracy: 71.66666666666667%\n",
            "Iteration: 500. Loss: 1.5446991920471191. Accuracy: 22.38095238095238%\n",
            "Iteration: 600. Loss: 2.1177279949188232. Accuracy: 37.61904761904762%\n",
            "Iteration: 700. Loss: 1.4603145122528076. Accuracy: 16.428571428571427%\n",
            "Iteration: 800. Loss: 1.9079666137695312. Accuracy: 36.666666666666664%\n",
            "Iteration: 900. Loss: 0.1386106014251709. Accuracy: 38.80952380952381%\n",
            "Iteration: 1000. Loss: 0.9919295310974121. Accuracy: 79.76190476190476%\n",
            "Iteration: 1100. Loss: 0.14926362037658691. Accuracy: 91.9047619047619%\n",
            "Iteration: 1200. Loss: 0.08057212829589844. Accuracy: 90.47619047619048%\n",
            "Iteration: 1300. Loss: 0.12791872024536133. Accuracy: 86.9047619047619%\n",
            "Iteration: 1400. Loss: 0.327470064163208. Accuracy: 78.57142857142857%\n",
            "Iteration: 1500. Loss: 0.011696815490722656. Accuracy: 94.52380952380952%\n",
            "Iteration: 1600. Loss: 0.037982940673828125. Accuracy: 94.52380952380952%\n",
            "EPOCH -- 1\n",
            "Iteration: 0. Loss: 0.1090841293334961. Accuracy: 93.33333333333333%\n",
            "Iteration: 100. Loss: 0.02671670913696289. Accuracy: 89.52380952380952%\n",
            "Iteration: 200. Loss: 0.05430412292480469. Accuracy: 79.52380952380952%\n",
            "Iteration: 300. Loss: 0.07218313217163086. Accuracy: 90.0%\n",
            "Iteration: 400. Loss: 0.0386052131652832. Accuracy: 95.23809523809524%\n",
            "Iteration: 500. Loss: 0.026149272918701172. Accuracy: 97.38095238095238%\n",
            "Iteration: 600. Loss: 0.018435955047607422. Accuracy: 87.14285714285714%\n",
            "Iteration: 700. Loss: 0.1638050079345703. Accuracy: 96.9047619047619%\n",
            "Iteration: 800. Loss: 2.61242938041687. Accuracy: 97.14285714285714%\n",
            "Iteration: 900. Loss: 0.017860889434814453. Accuracy: 94.76190476190476%\n",
            "Iteration: 1000. Loss: 0.008881092071533203. Accuracy: 98.57142857142857%\n",
            "Iteration: 1100. Loss: 0.014180660247802734. Accuracy: 66.66666666666667%\n",
            "Iteration: 1200. Loss: 0.006680965423583984. Accuracy: 97.38095238095238%\n",
            "Iteration: 1300. Loss: 1.6231801509857178. Accuracy: 97.85714285714286%\n",
            "Iteration: 1400. Loss: 0.011644840240478516. Accuracy: 94.28571428571429%\n",
            "Iteration: 1500. Loss: 0.007730007171630859. Accuracy: 86.66666666666667%\n",
            "Iteration: 1600. Loss: 0.01945018768310547. Accuracy: 97.85714285714286%\n",
            "EPOCH -- 2\n",
            "Iteration: 0. Loss: 0.012382984161376953. Accuracy: 92.61904761904762%\n",
            "Iteration: 100. Loss: 0.07142972946166992. Accuracy: 99.52380952380952%\n",
            "Iteration: 200. Loss: 0.019449710845947266. Accuracy: 98.57142857142857%\n",
            "Iteration: 300. Loss: 0.01268911361694336. Accuracy: 99.52380952380952%\n",
            "Iteration: 400. Loss: 0.039034366607666016. Accuracy: 93.57142857142857%\n",
            "Iteration: 500. Loss: 0.0058746337890625. Accuracy: 99.28571428571429%\n",
            "Iteration: 600. Loss: 0.012050628662109375. Accuracy: 99.52380952380952%\n",
            "Iteration: 700. Loss: 0.012622356414794922. Accuracy: 99.52380952380952%\n",
            "Iteration: 800. Loss: 0.011606693267822266. Accuracy: 98.57142857142857%\n",
            "Iteration: 900. Loss: 0.01425027847290039. Accuracy: 97.38095238095238%\n",
            "Iteration: 1000. Loss: 0.17160940170288086. Accuracy: 91.42857142857143%\n",
            "Iteration: 1100. Loss: 0.005035877227783203. Accuracy: 81.42857142857143%\n",
            "Iteration: 1200. Loss: 0.0188446044921875. Accuracy: 99.04761904761905%\n",
            "Iteration: 1300. Loss: 0.0084381103515625. Accuracy: 99.28571428571429%\n",
            "Iteration: 1400. Loss: 0.0071849822998046875. Accuracy: 97.85714285714286%\n",
            "Iteration: 1500. Loss: 0.00650787353515625. Accuracy: 97.85714285714286%\n",
            "Iteration: 1600. Loss: 0.006388187408447266. Accuracy: 99.76190476190476%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vM-buqhZOB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Save the Model\n",
        "\n",
        "Note - I have provided the trained model to you. Use that model to answer questions below.\n",
        "'''\n",
        "\n",
        "torch.save(model.state_dict(), 'drive/My Drive/2017-06-custom-intent-engines/roberta_state_dict_'+ str(uuid4())+'.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3ltBRa1ZOD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNPPlPp1csfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO1uVLH1csht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXBwJzkWcskd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BocwFm90csm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Note - \n",
        "\n",
        "1. Use the model I have given you, call it H\n",
        "2. Upload H to the exact path /My Drive/ in your google drive\n",
        "'''\n",
        "\n",
        "model_path = 'drive/My Drive/2017-06-custom-intent-engines/roberta_state_dict_2316b155-b288-4782-a927-1d3e7c02c968.pth'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzTSevnndSb1",
        "colab_type": "code",
        "outputId": "1b5f7ac4-1925-4de9-c265-f4debbbb98fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''\n",
        "Loading State dictionaries\n",
        "'''\n",
        "\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oxvjy_kdVfh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Exercise 1.\n",
        "\n",
        "1. Come up with a function that uses the model to take a sentence as input \n",
        "2. Score the sentence using the model and generate a prediction\n",
        "3. Return the prediction intent from the model\n",
        "\n",
        "Done correctly, you have to write 4 lines\n",
        "\n",
        "'''\n",
        "\n",
        "def get_reply(msg):\n",
        "  model.eval()\n",
        "  input_msg, _ = prepare_features(msg)\n",
        "  if torch.cuda.is_available():\n",
        "    #Send Input Message to CUDA\n",
        "    #Line - 1\n",
        "  #Use the model to generate probability vector  \n",
        "  #Line - 2\n",
        "  print(output)\n",
        "\n",
        "  #Use torch.max function to return the prediction index with highest probability. Check how to use torch.max?\n",
        "  #Line - 3\n",
        "\n",
        "  #Match prediction index to actual prediction label. Use the label_to_ix = {} dictionary we created earlier.\n",
        "  #Line - 4\n",
        "\n",
        "  return prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AINTj8C1HoeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uv2sChf0HohA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcDYGzxWZOF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Exercise 2. - Test your function on the following sentences\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izlI8_76df6t",
        "colab_type": "code",
        "outputId": "5bb09df3-9c66-4f67-eabf-f66fe6b43c02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "get_reply(\"sun shinnes all day\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.3798, -2.3614,  0.0549,  4.1121,  1.2865,  1.3850, -2.7650]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PlayMusic'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SaSB0xudf9R",
        "colab_type": "code",
        "outputId": "c43236d7-6dc5-4e68-9b81-fadd9a2c6bb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_reply(\"it is rainy in Sao Paulo\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'GetWeather'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96QRpAxadf_y",
        "colab_type": "code",
        "outputId": "9d823d39-9a35-4d46-c800-761b8ae4cb9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_reply(\"play radiohead song\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PlayMusic'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mln17chdmvV",
        "colab_type": "code",
        "outputId": "ccd3ef2d-348e-41d1-c955-5856535f7aa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_reply(\"Book tacos for me tonight\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'BookRestaurant'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIlzbvBKdmyE",
        "colab_type": "code",
        "outputId": "9e041aa0-c309-4cdc-9d81-6757990eeb22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_reply(\"Book a table for me tonight\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'BookRestaurant'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jfddLSidmz_",
        "colab_type": "code",
        "outputId": "40e5a1fd-01df-4d31-b534-428939f3eefb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_reply(\"I want BBQ tonight\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PlayMusic'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-e7DwJMdm2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Exercise - 3 [Open Ended]\n",
        "\n",
        "How would you use this model in a Chat Bot?\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}