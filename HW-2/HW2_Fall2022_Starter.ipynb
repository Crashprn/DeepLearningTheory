{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMbeGOjSPvgv4zJetWwvFs4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3ad084bf"},"source":["# Intro to pytorch with linear regression models "]},{"cell_type":"markdown","metadata":{"id":"e4162ef0"},"source":["The objective in this homework is to get familiarity with the basic building blocks in pytorch "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"acd2b405"},"outputs":[],"source":["import torch \n","import numpy as np\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","plt.style.use('ggplot')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ba960dc3"},"outputs":[],"source":["\n","def generate_poly_data(N, sigma):\n","    np.random.seed(100)\n","    x = np.random.uniform(low=-1, high=3, size=N)\n","    y = [2 * i ** 2 - 3 * i + 1 for i in x] \n","    noise = np.random.normal(0, sigma, N)\n","    y = y + noise\n","    return x, y\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8548c770"},"outputs":[],"source":["x, y = generate_poly_data(20, 0.5)\n","plt.scatter(x, y)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e59dce40"},"outputs":[],"source":["# Our test data \n","x_test = np.random.uniform(low=-1, high=3, size = 1000)\n","y_test = np.array([2 * i ** 2 - 3 * i + 1 for i in x_test]) \n","plt.scatter(x_test, y_test)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"badd0378"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"26887369"},"outputs":[],"source":["# We want y = wx + b\n","\n","class LinearReg_module(nn.Module):\n","    def __init__(self, input_dim):\n","        super().__init__()\n","        self.regressionLayer = nn.Linear(input_dim, 1)\n","    def forward(self, x):\n","        output = self.regressionLayer(x)\n","        return output \n","        \n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9c23d5e2"},"outputs":[],"source":["# Linear regression\n","\n","class pytorchLR():\n","    def __init__(self, \n","                 n_epochs = 100,\n","                weight_decay = 0,\n","                lr = 10e-3):\n","        self.n_epochs = n_epochs\n","        self.weight_decay = weight_decay\n","        self.lr = lr\n","        \n","    def fit(self, x, y):\n","        x = torch.tensor(x).float()\n","        y = torch.tensor(y).float()\n","        '''*** Define the loss ***\n","        '''\n","\n","        \n","        '''*** Define the optimizer SGD ***'''\n","\n","        \n","        for epoch in range(self.n_epochs):\n","            '''\n","            For this homework you are not required to partition the data in mini batches \n","            ***\n","            Complete the training routine passing x trhough the network, computing the loss, calling the backpropagation \n","            and computing an step with the optimizer\n","            ***\n","            '''\n","\n","\n","\n","            \n","    def predict(self, x):\n","        self.module.eval()\n","        x = torch.tensor(x).float()\n","        y_hat = self.module(x)\n","        return y_hat.detach().cpu().numpy()\n","            \n","        \n","        \n","        \n","        \n","        \n","    \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ec99acc6"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b8782711"},"outputs":[],"source":["# Create the model and fit it. For now the model is y = mx + b\n","model = pytorchLR(n_epochs = 5000, weight_decay = 0, lr = 1e-3)\n","model.fit(x[:, None], y[:, None])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ef4860ef"},"outputs":[],"source":["# Plot the predictions and the train data \n","y_hat = model.predict(x_test[:, None])\n","plt.scatter(x_test, y_hat)\n","plt.scatter(x_test, y_test, c = \"black\", s = 1)\n","plt.scatter(x, y)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"54e10179"},"outputs":[],"source":["# We known the true model is an 2nd order polynomial \n","'''*** Create the data for the x and x**2, fit the model, and plot as above the training data and the predictions of the test data.\n","Then print the parameters of your regressionLayer or your model.module.\n","Did you obtain something close to the true parameters?\n","***'''\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cb43abf6"},"outputs":[],"source":["'''*** Create the data for a 5 degree polynomial and fit it. Should you get a better MSE than for the previous two models?.\n","hint: you might need to play with the learning rate until you obtain a good value\n","***'''\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"942e79b3"},"outputs":[],"source":["'''*** Create a for loop for different values of sigma = [0.1, 0.5, 1], and N = [15, 100]\n","use a 5 degree polynomial model with different values for regularization \n","weight_decay = [0, 0.2, 0.5], compute the testing error \n","***'''\n"," "]}]}