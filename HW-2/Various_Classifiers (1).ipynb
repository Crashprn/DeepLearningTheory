{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    ".....IMPORTANT USAGE INSTRUCTIONS........\n",
    "\n",
    "##### IF USING CHPC - UTAH #####\n",
    "\n",
    "1. Download this Jupyter Notebook to a local location on your Computer\n",
    "2. Go to https://ondemand.chpc.utah.edu and sign in using your uNID and Password.\n",
    "3. At the Top of the Page, notice the Menu \"Interactive Apps\". Click and Choose \"Jupyter Notebook on Notchpeak\"\n",
    "4. A form will open, enter all details, and then Launch a Jupyter Notebook. It will take a minute.\n",
    "5. Click on \"Connect to Jupyter\"\n",
    "6. Once Jupyter Launches. On Top Right Notice \"Upload Button\". Use this to Upload this Notebook.\n",
    "7. The Notebook will be uploaded. Finish writing the Code whereever specified.\n",
    "8. Run each Block of Code and then finally download the Jupyter Notebook by going to File >> Download as >>\n",
    "\n",
    "\n",
    "##### IF USING GOOGLE COLAB #####\n",
    "\n",
    "1. Download this Jupyter Notebook to a local location on your Computer\n",
    "2. Go to https://colab.research.google.com/ and sign in using your Google Account - So that your work is saved in\n",
    "   your Google Drive permanently.\n",
    "3. Go to File >> Upload Notebook.\n",
    "4. Finish writing the Code whereever specified.\n",
    "5. Run each Block of Code ad then finally download the Jupyter Notebook by going to File >> Download .ipynb\n",
    "\n",
    "'''"
   ]
  },
  
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Problem 1 - Refer to your own code from HW - 1\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Problem 2.1 - Code has been given to you. Make sure you understand every line of the import step and data structuring\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "from collections import Counter\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "#Matplotlib Settings with ggplot Theme\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Fixing random state for reproducibility\n",
    "np.random.seed(19680801)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Data Import and Preprocessing\n",
    "\n",
    "'''\n",
    "Note : The dataset data_seed.dat can be downloaded from Canvas or github. In this notebook, I have placed this file\n",
    "       directly under my home directory indicated by ~/.\n",
    "       \n",
    "       In CHPC - Your home directory is /uufs/cpc.utah.edu/common/home/<uNID>\n",
    "       \n",
    "       In Google Colab - On the Left Hand Menu, Click on Files and then Upload this data file.\n",
    "\n",
    "'''\n",
    "\n",
    "#Import Data File into Pandas - 210 Rows and 8 Columns. The dataset has no columns\n",
    "df = pd.read_csv('~/data_seed.dat', sep='\\s+', header=None, skiprows=0)\n",
    "\n",
    "#Add Column Names\n",
    "df.columns = ['A', 'P', 'C', 'L_Kern','W_Kern', 'Asy_Coeff','L_Kern_Grv','Y']\n",
    "\n",
    "#Scale X Columns -  The idea is to Scale each column in the dataset using built in Standard Scaler\n",
    "cols_to_norm = ['A', 'P', 'C', 'L_Kern','W_Kern', 'Asy_Coeff','L_Kern_Grv']\n",
    "df[cols_to_norm] = StandardScaler().fit_transform(df[cols_to_norm])\n",
    "\n",
    "#Shuffle the Dataset and then split into 5 separate dataframes to be used later for CV\n",
    "seeds = shuffle(df)\n",
    "\n",
    "#Split shuffled data into 5 data frames of size 42 each.\n",
    "split_size = int(seeds.shape[0]/5)\n",
    "\n",
    "fold_1 = seeds.iloc[0:split_size]\n",
    "fold_2 = seeds.iloc[split_size: 2*split_size]\n",
    "fold_3 = seeds.iloc[2*split_size: 3*split_size]\n",
    "fold_4 = seeds.iloc[3*split_size: 4*split_size]\n",
    "fold_5 = seeds.iloc[4*split_size: 5*split_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>P</th>\n",
       "      <th>C</th>\n",
       "      <th>L_Kern</th>\n",
       "      <th>W_Kern</th>\n",
       "      <th>Asy_Coeff</th>\n",
       "      <th>L_Kern_Grv</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.142098</td>\n",
       "      <td>0.215462</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.304218</td>\n",
       "      <td>0.141702</td>\n",
       "      <td>-0.986152</td>\n",
       "      <td>-0.383577</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011188</td>\n",
       "      <td>0.008224</td>\n",
       "      <td>0.428515</td>\n",
       "      <td>-0.168625</td>\n",
       "      <td>0.197432</td>\n",
       "      <td>-1.788166</td>\n",
       "      <td>-0.922013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.192067</td>\n",
       "      <td>-0.360201</td>\n",
       "      <td>1.442383</td>\n",
       "      <td>-0.763637</td>\n",
       "      <td>0.208048</td>\n",
       "      <td>-0.667479</td>\n",
       "      <td>-1.189192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.347091</td>\n",
       "      <td>-0.475333</td>\n",
       "      <td>1.039381</td>\n",
       "      <td>-0.688978</td>\n",
       "      <td>0.319508</td>\n",
       "      <td>-0.960818</td>\n",
       "      <td>-1.229983</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.445257</td>\n",
       "      <td>0.330595</td>\n",
       "      <td>1.374509</td>\n",
       "      <td>0.066666</td>\n",
       "      <td>0.805159</td>\n",
       "      <td>-1.563495</td>\n",
       "      <td>-0.475356</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         P         C    L_Kern    W_Kern  Asy_Coeff  L_Kern_Grv  Y\n",
       "0  0.142098  0.215462  0.000061  0.304218  0.141702  -0.986152   -0.383577  1\n",
       "1  0.011188  0.008224  0.428515 -0.168625  0.197432  -1.788166   -0.922013  1\n",
       "2 -0.192067 -0.360201  1.442383 -0.763637  0.208048  -0.667479   -1.189192  1\n",
       "3 -0.347091 -0.475333  1.039381 -0.688978  0.319508  -0.960818   -1.229983  1\n",
       "4  0.445257  0.330595  1.374509  0.066666  0.805159  -1.563495   -0.475356  1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's Check how the dataset looks like\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Problem 2.2 - Fill in the missing pieces for the k-NN implementation. Use the rest of the code to generate \n",
    "necessary metrics\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Fit k-NN\n",
    "'''\n",
    "\n",
    "#Define all k's that we want to try for k-NN. We don't know k apriori, so we need to grid search.\n",
    "k_try = [1,5,10,15]\n",
    "\n",
    "\n",
    "#Function that finds Euclidean Distance Between Points. These two points are in the form of numpy lists.\n",
    "def pair_euclid_dist(a,b):\n",
    "    return numpy.linalg.norm(a-b)\n",
    "    \n",
    "\n",
    "def knn_accuracy(ds,k):\n",
    "    '''\n",
    "    This function evaluates the accuracy of a knn-classifier for a given k for any \n",
    "    given dataset\n",
    "    \n",
    "    Notation:\n",
    "    \n",
    "    ds = Input Dataset\n",
    "    k = k in k-NN\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #Accuracy Counter\n",
    "    \n",
    "    ctr = 0\n",
    "    \n",
    "    #Initialize Dictionaries\n",
    "    dists = {}\n",
    "    res = {}\n",
    "    \n",
    "    #Pouplate the Dictionary with key = row_ids and values as empty list in dists\n",
    "    # and key = row_ids and values = actual class of row_id in res\n",
    "    for row1 in ds.iterrows():\n",
    "        dists[list(row1)[0]] = []\n",
    "        res[list(row1)[0]] = [(list(row1)[1][7])]\n",
    "    \n",
    "    #Use the Distance Metric to evaluate Distance of every point with every other point\n",
    "    for row1 in ds.iterrows():\n",
    "        for row2 in ds.iterrows():\n",
    "            \n",
    "            '''Exercise - Use the pair_euclid_dist function from above to calculate pair wise distances\n",
    "            '''\n",
    "            \n",
    "            '''Exercise - sort the distances for every row_id\n",
    "            '''\n",
    "        \n",
    "                \n",
    "        '''Exercise - Take the classes of only k closest points\n",
    "        '''\n",
    "        for g in range(1,k+1): \n",
    "            ...\n",
    "                    \n",
    "        '''Exercise - Take Vote\n",
    "        '''\n",
    "        vote = ...\n",
    "        \n",
    "        #Compare if the vote with true value\n",
    "        if vote == res[list(row1)[0]][0]:\n",
    "            ctr = ctr + 1 #Increment Accuracy Counter\n",
    "            \n",
    "    return(ctr/ds.shape[0])\n",
    "\n",
    "\n",
    "#Function that estimates Accuracy of the k-nn classifier using 5 fold Cross Validation\n",
    "def knn_cv(fold_1,fold_2,fold_3,fold_4,fold_5):\n",
    "    '''\n",
    "    This function iterates through the various values of k and prints out the average \n",
    "    accuracy using CV \n",
    "    '''\n",
    "    #Iterate over all values of the tuning Parameter\n",
    "    for trial in k_try:\n",
    "        #Try k-nn for each fold and Average the Classification Accuracy\n",
    "        a = knn_accuracy(fold_1, trial)\n",
    "        b = knn_accuracy(fold_2, trial)\n",
    "        c = knn_accuracy(fold_3, trial)\n",
    "        d = knn_accuracy(fold_4, trial)\n",
    "        e = knn_accuracy(fold_5, trial)\n",
    "        print('CV - 5 Accuracy for k_try = ',trial, ' is: ', np.mean([a,b,c,d,e]))\n",
    "\n",
    "#Function that estimates Accuracy of the k-nn classifier using Leave One out Validation\n",
    "def knn_loocv(full_set):\n",
    "    '''\n",
    "    This function iterates through the various values of k and prints out the average \n",
    "    accuracy using LOOCV \n",
    "    '''\n",
    "    #Iterate over all values of the tuning Parameter\n",
    "    for trial in k_try:\n",
    "        \n",
    "        '''Exercise - Fill in the code here to do LOOCV\n",
    "        '''\n",
    "        \n",
    "        print('LOOCV Accuracy for k_try = ',trial, ' is: ', z)\n",
    "    \n",
    "\n",
    "#Fit KNN with CV = 5   \n",
    "knn_cv(fold_1,fold_2,fold_3,fold_4,fold_5)\n",
    "\n",
    "\n",
    "#Fit KNN with LOOCV      \n",
    "knn_loocv(seeds) #Remember seeds is the name of our full dataset.\n",
    "\n",
    "#Plotting Test Errors from both 5 fold CV and LOOCV\n",
    "\n",
    "'''\n",
    "Exercise\n",
    "Line plot of errors for each k for 5 fold CV\n",
    "Line plot of errors for each k for LOOCV\n",
    "\n",
    "Remark:\n",
    "\n",
    "Make sure the plot is properly labeled.\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Problem 2.3 - The following example shows steps to call an inbuilt classifier (Random Forest) from Scikit Learn. \n",
    "Choose two other classifiers from scikit-learn to solve this problem. The sequence of steps will be roughly the same.\n",
    "\n",
    "Note : Do not use Random Forests (because we want you to learn to fit your own classifiers). \n",
    "To see a list of available list of classifiers, run the code block below\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''Prints a list of available inbuilt classifiers'''\n",
    "\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.utils.testing import all_estimators\n",
    "classifiers=[est for est in all_estimators() if issubclass(est[1], ClassifierMixin)]\n",
    "for classifier in classifiers:\n",
    "    print(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uufs/chpc.utah.edu/common/home/u6022720/.local/lib/python3.5/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF - Best Params =  {'n_estimators': 50, 'max_features': 'log2'}\n",
      "CV - 5 : Accuracy Score =  0.9455782312925171\n",
      "Test Set Accuracy =  0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "'''Random Forest'''\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Define X, y\n",
    "X = seeds[['A', 'P', 'C', 'L_Kern','W_Kern', 'Asy_Coeff','L_Kern_Grv']]\n",
    "y = seeds['Y']\n",
    "\n",
    "#Test Train Split - Using the Built in Method.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "#Initialize the RF Classifier\n",
    "rfc = RandomForestClassifier(n_jobs=-1,max_features= 'sqrt' ,n_estimators=50, oob_score = True) \n",
    "\n",
    "#Define Parameter Grid to perform Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "#Initiate Grid Search\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "\n",
    "#Fit Model with Grid Search\n",
    "CV_rfc.fit(X_train,y_train)\n",
    "\n",
    "#Training Accuracy\n",
    "print('RF - Best Params = ',CV_rfc.best_params_)\n",
    "print('CV - 5 : Accuracy Score = ',CV_rfc.best_score_ )\n",
    "\n",
    "#Test Accuracy\n",
    "print('Test Set Accuracy = ', CV_rfc.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
