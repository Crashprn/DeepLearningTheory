{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yvMlDjs63TBG",
    "outputId": "23308019-5285-4ec1-d418-a90636000535"
   },
   "outputs": [],
   "source": [
    "#### CRITICAL - ENABLE GPU \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, re\n",
    "from tqdm import tqdm_notebook\n",
    "from uuid import uuid4\n",
    "\n",
    "## Torch Modules\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "## Mount Drive into Colab\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6_ppFOaeJxHD",
    "outputId": "046e77f0-81ef-4f6f-ba4b-7cdf60baea3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pytorch-transformers in /home/codygrogan/.local/lib/python3.11/site-packages (1.2.0)\n",
      "Requirement already satisfied: torch>=1.0.0 in /home/codygrogan/.local/lib/python3.11/site-packages (from pytorch-transformers) (2.0.1+cu118)\n",
      "Requirement already satisfied: numpy in /home/codygrogan/.local/lib/python3.11/site-packages (from pytorch-transformers) (1.24.3)\n",
      "Requirement already satisfied: boto3 in /home/codygrogan/.local/lib/python3.11/site-packages (from pytorch-transformers) (1.33.3)\n",
      "Requirement already satisfied: requests in /usr/lib/python3.11/site-packages (from pytorch-transformers) (2.28.2)\n",
      "Requirement already satisfied: tqdm in /home/codygrogan/.local/lib/python3.11/site-packages (from pytorch-transformers) (4.66.1)\n",
      "Requirement already satisfied: regex in /usr/lib64/python3.11/site-packages (from pytorch-transformers) (2023.10.3)\n",
      "Requirement already satisfied: sentencepiece in /home/codygrogan/.local/lib/python3.11/site-packages (from pytorch-transformers) (0.1.99)\n",
      "Requirement already satisfied: sacremoses in /home/codygrogan/.local/lib/python3.11/site-packages (from pytorch-transformers) (0.1.1)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3.11/site-packages (from torch>=1.0.0->pytorch-transformers) (3.8.2)\n",
      "Requirement already satisfied: typing-extensions in /home/codygrogan/.local/lib/python3.11/site-packages (from torch>=1.0.0->pytorch-transformers) (4.5.0)\n",
      "Requirement already satisfied: sympy in /home/codygrogan/.local/lib/python3.11/site-packages (from torch>=1.0.0->pytorch-transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/codygrogan/.local/lib/python3.11/site-packages (from torch>=1.0.0->pytorch-transformers) (3.0)\n",
      "Requirement already satisfied: jinja2 in /home/codygrogan/.local/lib/python3.11/site-packages (from torch>=1.0.0->pytorch-transformers) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/codygrogan/.local/lib/python3.11/site-packages (from torch>=1.0.0->pytorch-transformers) (2.0.0)\n",
      "Requirement already satisfied: cmake in /home/codygrogan/.local/lib/python3.11/site-packages (from triton==2.0.0->torch>=1.0.0->pytorch-transformers) (3.25.0)\n",
      "Requirement already satisfied: lit in /home/codygrogan/.local/lib/python3.11/site-packages (from triton==2.0.0->torch>=1.0.0->pytorch-transformers) (15.0.7)\n",
      "Requirement already satisfied: botocore<1.34.0,>=1.33.3 in /home/codygrogan/.local/lib/python3.11/site-packages (from boto3->pytorch-transformers) (1.33.3)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/codygrogan/.local/lib/python3.11/site-packages (from boto3->pytorch-transformers) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.9.0,>=0.8.0 in /home/codygrogan/.local/lib/python3.11/site-packages (from boto3->pytorch-transformers) (0.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/python3.11/site-packages (from requests->pytorch-transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.11/site-packages (from requests->pytorch-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3.11/site-packages (from requests->pytorch-transformers) (1.26.18)\n",
      "Requirement already satisfied: click in /usr/lib/python3.11/site-packages (from sacremoses->pytorch-transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in /home/codygrogan/.local/lib/python3.11/site-packages (from sacremoses->pytorch-transformers) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/lib/python3.11/site-packages (from botocore<1.34.0,>=1.33.3->boto3->pytorch-transformers) (2.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib64/python3.11/site-packages (from jinja2->torch>=1.0.0->pytorch-transformers) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/codygrogan/.local/lib/python3.11/site-packages (from sympy->torch>=1.0.0->pytorch-transformers) (1.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.34.0,>=1.33.3->boto3->pytorch-transformers) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UFaPT_uM5YJL"
   },
   "outputs": [],
   "source": [
    "## PyTorch Transformer\n",
    "from pytorch_transformers import RobertaModel, RobertaTokenizer\n",
    "from pytorch_transformers import RobertaForSequenceClassification, RobertaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KRzo1v6D4O2t",
    "outputId": "7a4b7dd0-97fd-47b5-8d83-188b7037fb1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "## Check if Cuda is Available\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGnE-bXo3-77"
   },
   "source": [
    "## Install PyTorch-Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Put6o1wF3-yk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pytorch-transformers in /home/codygrogan/.local/lib/python3.11/site-packages (1.2.0)\n",
      "Requirement already satisfied: torch>=1.0.0 in /home/codygrogan/.local/lib/python3.11/site-packages (from pytorch-transformers) (2.0.1+cu118)\n",
      "Requirement already satisfied: numpy in /home/codygrogan/.local/lib/python3.11/site-packages (from pytorch-transformers) (1.24.3)\n",
      "Requirement already satisfied: boto3 in /home/codygrogan/.local/lib/python3.11/site-packages (from pytorch-transformers) (1.33.3)\n",
      "Requirement already satisfied: requests in /usr/lib/python3.11/site-packages (from pytorch-transformers) (2.28.2)\n",
      "Requirement already satisfied: tqdm in /home/codygrogan/.local/lib/python3.11/site-packages (from pytorch-transformers) (4.66.1)\n",
      "Requirement already satisfied: regex in /usr/lib64/python3.11/site-packages (from pytorch-transformers) (2023.10.3)\n",
      "Requirement already satisfied: sentencepiece in /home/codygrogan/.local/lib/python3.11/site-packages (from pytorch-transformers) (0.1.99)\n",
      "Requirement already satisfied: sacremoses in /home/codygrogan/.local/lib/python3.11/site-packages (from pytorch-transformers) (0.1.1)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3.11/site-packages (from torch>=1.0.0->pytorch-transformers) (3.8.2)\n",
      "Requirement already satisfied: typing-extensions in /home/codygrogan/.local/lib/python3.11/site-packages (from torch>=1.0.0->pytorch-transformers) (4.5.0)\n",
      "Requirement already satisfied: sympy in /home/codygrogan/.local/lib/python3.11/site-packages (from torch>=1.0.0->pytorch-transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/codygrogan/.local/lib/python3.11/site-packages (from torch>=1.0.0->pytorch-transformers) (3.0)\n",
      "Requirement already satisfied: jinja2 in /home/codygrogan/.local/lib/python3.11/site-packages (from torch>=1.0.0->pytorch-transformers) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/codygrogan/.local/lib/python3.11/site-packages (from torch>=1.0.0->pytorch-transformers) (2.0.0)\n",
      "Requirement already satisfied: cmake in /home/codygrogan/.local/lib/python3.11/site-packages (from triton==2.0.0->torch>=1.0.0->pytorch-transformers) (3.25.0)\n",
      "Requirement already satisfied: lit in /home/codygrogan/.local/lib/python3.11/site-packages (from triton==2.0.0->torch>=1.0.0->pytorch-transformers) (15.0.7)\n",
      "Requirement already satisfied: botocore<1.34.0,>=1.33.3 in /home/codygrogan/.local/lib/python3.11/site-packages (from boto3->pytorch-transformers) (1.33.3)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/codygrogan/.local/lib/python3.11/site-packages (from boto3->pytorch-transformers) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.9.0,>=0.8.0 in /home/codygrogan/.local/lib/python3.11/site-packages (from boto3->pytorch-transformers) (0.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/python3.11/site-packages (from requests->pytorch-transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.11/site-packages (from requests->pytorch-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3.11/site-packages (from requests->pytorch-transformers) (1.26.18)\n",
      "Requirement already satisfied: click in /usr/lib/python3.11/site-packages (from sacremoses->pytorch-transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in /home/codygrogan/.local/lib/python3.11/site-packages (from sacremoses->pytorch-transformers) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/lib/python3.11/site-packages (from botocore<1.34.0,>=1.33.3->boto3->pytorch-transformers) (2.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib64/python3.11/site-packages (from jinja2->torch>=1.0.0->pytorch-transformers) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/codygrogan/.local/lib/python3.11/site-packages (from sympy->torch>=1.0.0->pytorch-transformers) (1.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.34.0,>=1.33.3->boto3->pytorch-transformers) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pytorch-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkRqK2sM3evs"
   },
   "source": [
    "## Importing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HIqwXlCy4g-U",
    "outputId": "19ae84e8-8f1b-4e6c-b606-b1558073d1a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AddToPlaylist\tGetWeather  RateBook   SearchCreativeWork\n",
      "BookRestaurant\tPlayMusic   README.md  SearchScreeningEvent\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Important Step - Make sure you upload the data file to the exact location below. If you uploaded correctlt, the following command will run\n",
    "'''\n",
    "\n",
    "! ls 2017-06-custom-intent-engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "uudmDs_U39YL"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Create the Dataset Path\n",
    "'''\n",
    "\n",
    "\n",
    "dataset_path = \"2017-06-custom-intent-engines/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "mJi5RkLC4WsV",
    "outputId": "d9bbc592-bfcc-438c-9bf4-9495781382f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: AddToPlaylist, # utterances: 300\n",
      "Class: BookRestaurant, # utterances: 300\n",
      "Class: GetWeather, # utterances: 300\n",
      "Class: PlayMusic, # utterances: 300\n",
      "Class: RateBook, # utterances: 300\n",
      "Class: SearchCreativeWork, # utterances: 300\n",
      "Class: SearchScreeningEvent, # utterances: 300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>Is Across the Line playing at the closest movi...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>Which animated movies are playing in the neigh...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>Where is They Always Return at Dawn playing</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>What is the movie schedule in the neighborhood</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>Tell me when Howling II: Your Sister Is a Were...</td>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              utterance                 label\n",
       "2095  Is Across the Line playing at the closest movi...  SearchScreeningEvent\n",
       "2096  Which animated movies are playing in the neigh...  SearchScreeningEvent\n",
       "2097        Where is They Always Return at Dawn playing  SearchScreeningEvent\n",
       "2098     What is the movie schedule in the neighborhood  SearchScreeningEvent\n",
       "2099  Tell me when Howling II: Your Sister Is a Were...  SearchScreeningEvent"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "***Explain*** Summarize, in bullet points, what is the code doing?. \n",
    "'''\n",
    "\n",
    "dataset = pd.DataFrame(columns = ['utterance', 'label'])\n",
    "for intent in ['AddToPlaylist', 'BookRestaurant', 'GetWeather', 'PlayMusic', 'RateBook', 'SearchCreativeWork',\n",
    "               'SearchScreeningEvent']:\n",
    "    with open(dataset_path + intent + \"/train_\" + intent + \".json\",\n",
    "              encoding='cp1251') as data_file:\n",
    "        data = json.load(data_file)\n",
    "    print(\"Class: {}, # utterances: {}\".format(intent,len(data[intent])))\n",
    "    texts = []\n",
    "    for i in range(len(data[intent])):\n",
    "        text = ''\n",
    "        for j in range(len(data[intent][i]['data'])):\n",
    "            text += data[intent][i]['data'][j]['text']\n",
    "        dataset = pd.concat([dataset, pd.DataFrame([{'utterance': text, 'label': intent}])], ignore_index=True)\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gvNXPtT-4Xed",
    "outputId": "3199ab27-bfeb-4bfd-9296-2809e3e8016c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AddToPlaylist': 0,\n",
       " 'BookRestaurant': 1,\n",
       " 'GetWeather': 2,\n",
       " 'PlayMusic': 3,\n",
       " 'RateBook': 4,\n",
       " 'SearchCreativeWork': 5,\n",
       " 'SearchScreeningEvent': 6}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Assigning an Index to each intent. We will use this later\n",
    "'''\n",
    "\n",
    "'''\n",
    "***Explain*** Why do we convert labels to indexes?. \n",
    "'''\n",
    "\n",
    "label_to_ix = {}\n",
    "for label in dataset.label:\n",
    "    for word in label.split():\n",
    "        if word not in label_to_ix:\n",
    "            label_to_ix[word]=len(label_to_ix)\n",
    "label_to_ix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FtiQj3n5Qqo"
   },
   "source": [
    "## Loading RoBERTa classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ALqUM9f5Qnx",
    "outputId": "07ff5dac-bc51-4085-8171-c29bbaac1069"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"architectures\": [\n",
       "    \"RobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"finetuning_task\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"num_labels\": 7,\n",
       "  \"output_attentions\": false,\n",
       "  \"output_hidden_states\": false,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"pruned_heads\": {},\n",
       "  \"torchscript\": false,\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = RobertaConfig.from_pretrained('roberta-base')\n",
    "config.num_labels = len(list(label_to_ix.values()))\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "b65wR6MO5Qkm"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Loading Pretrained tokenizer and instantiating the model from settings in config\n",
    "'''\n",
    "\n",
    "'''\n",
    "***Explain*** : a. What is a tokenizer? b. What is special about the following tokenizer?. \n",
    "'''\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "'''\n",
    "***Explain*** :  What is the next line doing?\n",
    "'''\n",
    "\n",
    "model = RobertaForSequenceClassification(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGKN5aD85Bje"
   },
   "source": [
    "## Feature Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qf0ATRkF5LEx"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Some important Feature Engineering\n",
    "'''\n",
    "\n",
    "'''\n",
    "***Explain*** : What are the implications for setting  include_CLS_token = True, include_SEP_token = True ?\n",
    "'''\n",
    "\n",
    "def prepare_features(seq_1, max_seq_length = 300, \n",
    "             zero_pad = False, include_CLS_token = True, include_SEP_token = True):\n",
    "    ## Tokenzine Input\n",
    "    tokens_a = tokenizer.tokenize(seq_1)\n",
    "\n",
    "    ## Truncate\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
    "    ## Initialize Tokens\n",
    "    tokens = []\n",
    "    if include_CLS_token:\n",
    "        tokens.append(tokenizer.cls_token)\n",
    "    ## Add Tokens and separators\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "\n",
    "    if include_SEP_token:\n",
    "        tokens.append(tokenizer.sep_token)\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    ## Input Mask \n",
    "    input_mask = [1] * len(input_ids)\n",
    "    ## Zero-pad sequence lenght\n",
    "    if zero_pad:\n",
    "        while len(input_ids) < max_seq_length:\n",
    "            input_ids.append(0)\n",
    "            input_mask.append(0)\n",
    "    return torch.tensor(input_ids).unsqueeze(0), input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JDx-QxmX5Muc",
    "outputId": "05b15556-4d95-452c-c5e3-fc2f54b3af96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    0,  1308,  2335,    16, 11962,   328,     2]]),\n",
       " [1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg = \"My dog is cute!\"\n",
    "prepare_features(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pNqrigh5OIZ"
   },
   "source": [
    "## Dataset Loader Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Pexochza5lZq"
   },
   "outputs": [],
   "source": [
    "class Intents(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        utterance = self.data.utterance[index]\n",
    "        label = self.data.label[index]\n",
    "        X, _  = prepare_features(utterance)\n",
    "        y = label_to_ix[self.data.label[index]]\n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "oCiCHdRL5mH1"
   },
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "train_dataset=dataset.sample(frac=train_size,random_state=200).reset_index(drop=True)\n",
    "test_dataset=dataset.drop(train_dataset.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fqOFntri5yW-",
    "outputId": "84da9544-5a8f-4b73-9d7c-456261819062"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (2100, 2)\n",
      "TRAIN Dataset: (1680, 2)\n",
      "TEST Dataset: (420, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"FULL Dataset: {}\".format(dataset.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "zJkGxTWZ5z5d"
   },
   "outputs": [],
   "source": [
    "training_set = Intents(train_dataset)\n",
    "testing_set = Intents(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "guYUIlVN51gE",
    "outputId": "5a5e72f5-e069-4804-e13a-ee16931aa0ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.__getitem__(0)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iuCpzlBq52qV",
    "outputId": "99bceef7-504c-48f1-cfe9-583331a3eb31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.2699e-01, -1.7851e-01,  7.2745e-02, -4.3752e-05,  6.3752e-03,\n",
       "          -1.7097e-01,  2.1368e-01]], grad_fn=<AddmmBackward0>),)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(training_set.__getitem__(0)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3SH63pK5339"
   },
   "source": [
    "## Training Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "yYQq5eSi55mZ"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "H6MIe-fe6PY2"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {'batch_size': 1,\n",
    "          'shuffle': True,\n",
    "          'drop_last': False,\n",
    "          'num_workers': 1\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "egs1bYCe6UOL"
   },
   "outputs": [],
   "source": [
    "training_loader = DataLoader(training_set, **params)\n",
    "testing_loader = DataLoader(testing_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "0RfrS14A6WGV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaForSequenceClassification(\n",
      "  (roberta): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(514, 768)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (classifier): RobertaClassificationHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Instantiate the Loss\n",
    "'''\n",
    "'''\n",
    "***Explain*** why cross entropy loss?, also print the model and explain why are not we using softmax at the end?\n",
    "'''\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-05\n",
    "optimizer = optim.Adam(params =  model.parameters(), lr=learning_rate)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-n3p7ncn6Xst",
    "outputId": "fe5ccff6-39f8-42ad-b1e2-f0dfa27e3e66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7])\n"
     ]
    }
   ],
   "source": [
    "## Test Forward Pass\n",
    "inp = training_set.__getitem__(0)[0].cuda()\n",
    "output = model(inp)[0]\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "AahQQllgKQ4F",
    "outputId": "39e14630-d1a7-467b-9efa-28d89df03770"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1+cu118'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "cffaf4cc325449c6a7d4670acf3177cf",
      "95675c0005b84a53980b5592204476a3",
      "45ee40a7fb6342309758f174eca9beae",
      "ef195bee3c7648c8ac9aa214cfb214e2",
      "a66c8919baf3401e8b5cf43383de7487",
      "8fe4100312e14bb388c58722e8077176",
      "262a34a2d7d54c05bdece96a627f5239",
      "fc008e0c33104fafbb90e6f335d55357"
     ]
    },
    "id": "xoRJhLY06evJ",
    "outputId": "0de706d6-535d-4fda-ff2f-eb83aaeecb3b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19050/1510112102.py:12: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for epoch in tqdm_notebook(range(max_epochs)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52426ee32bb24c9fa298a0a80672ef25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH -- 0\n",
      "Iteration: 0. Loss: 1.5319921970367432. Accuracy: 71.42857142857143%\n",
      "Iteration: 100. Loss: 1.5659877061843872. Accuracy: 0.0%\n",
      "Iteration: 200. Loss: 1.8033266067504883. Accuracy: 67.61904761904762%\n",
      "Iteration: 300. Loss: 1.6214380264282227. Accuracy: 3.5714285714285716%\n",
      "Iteration: 400. Loss: 2.1860790252685547. Accuracy: 28.571428571428573%\n",
      "Iteration: 500. Loss: 1.1266999244689941. Accuracy: 17.38095238095238%\n",
      "Iteration: 600. Loss: 1.0576212406158447. Accuracy: 15.952380952380953%\n",
      "Iteration: 700. Loss: 1.2241374254226685. Accuracy: 38.80952380952381%\n",
      "Iteration: 800. Loss: 0.6245338916778564. Accuracy: 56.904761904761905%\n",
      "Iteration: 900. Loss: 0.27856847643852234. Accuracy: 50.0%\n",
      "Iteration: 1000. Loss: 0.016908885911107063. Accuracy: 33.333333333333336%\n",
      "Iteration: 1100. Loss: 0.060578059405088425. Accuracy: 93.33333333333333%\n",
      "Iteration: 1200. Loss: 0.8997507095336914. Accuracy: 79.04761904761905%\n",
      "Iteration: 1300. Loss: 0.049345821142196655. Accuracy: 71.42857142857143%\n",
      "Iteration: 1400. Loss: 0.1121838390827179. Accuracy: 84.76190476190476%\n",
      "Iteration: 1500. Loss: 0.16612520813941956. Accuracy: 79.52380952380952%\n",
      "Iteration: 1600. Loss: 0.04213498905301094. Accuracy: 93.80952380952381%\n",
      "EPOCH -- 1\n",
      "Iteration: 0. Loss: 0.024873074144124985. Accuracy: 93.33333333333333%\n",
      "Iteration: 100. Loss: 1.3466832637786865. Accuracy: 95.47619047619048%\n",
      "Iteration: 200. Loss: 0.012101680971682072. Accuracy: 94.76190476190476%\n",
      "Iteration: 300. Loss: 0.011833470314741135. Accuracy: 94.28571428571429%\n",
      "Iteration: 400. Loss: 0.01366345677524805. Accuracy: 62.61904761904762%\n",
      "Iteration: 500. Loss: 0.06639662384986877. Accuracy: 57.857142857142854%\n",
      "Iteration: 600. Loss: 0.5954803824424744. Accuracy: 95.95238095238095%\n",
      "Iteration: 700. Loss: 0.01855539344251156. Accuracy: 95.71428571428571%\n",
      "Iteration: 800. Loss: 0.0063219089061021805. Accuracy: 92.85714285714286%\n",
      "Iteration: 900. Loss: 0.03249314799904823. Accuracy: 96.66666666666667%\n",
      "Iteration: 1000. Loss: 0.04099211469292641. Accuracy: 91.19047619047619%\n",
      "Iteration: 1100. Loss: 0.015960555523633957. Accuracy: 97.14285714285714%\n",
      "Iteration: 1200. Loss: 0.021157870069146156. Accuracy: 98.33333333333333%\n",
      "Iteration: 1300. Loss: 0.012795725837349892. Accuracy: 99.52380952380952%\n",
      "Iteration: 1400. Loss: 0.0060195582918822765. Accuracy: 95.0%\n",
      "Iteration: 1500. Loss: 0.32105422019958496. Accuracy: 96.19047619047619%\n",
      "Iteration: 1600. Loss: 0.019675912335515022. Accuracy: 93.57142857142857%\n",
      "EPOCH -- 2\n",
      "Iteration: 0. Loss: 0.020481986925005913. Accuracy: 85.23809523809524%\n",
      "Iteration: 100. Loss: 0.011160802096128464. Accuracy: 97.14285714285714%\n",
      "Iteration: 200. Loss: 0.0085640549659729. Accuracy: 98.33333333333333%\n",
      "Iteration: 300. Loss: 0.008004373870790005. Accuracy: 99.28571428571429%\n",
      "Iteration: 400. Loss: 0.006715822499245405. Accuracy: 96.66666666666667%\n",
      "Iteration: 500. Loss: 0.006891055963933468. Accuracy: 97.38095238095238%\n",
      "Iteration: 600. Loss: 0.00494744349271059. Accuracy: 73.80952380952381%\n",
      "Iteration: 700. Loss: 0.010191897861659527. Accuracy: 94.52380952380952%\n",
      "Iteration: 800. Loss: 0.0048182569444179535. Accuracy: 45.95238095238095%\n",
      "Iteration: 900. Loss: 1.394181728363037. Accuracy: 90.0%\n",
      "Iteration: 1000. Loss: 0.005916700232774019. Accuracy: 99.28571428571429%\n",
      "Iteration: 1100. Loss: 0.006285659968852997. Accuracy: 98.57142857142857%\n",
      "Iteration: 1200. Loss: 0.01987331360578537. Accuracy: 90.23809523809524%\n",
      "Iteration: 1300. Loss: 0.0067675672471523285. Accuracy: 83.0952380952381%\n",
      "Iteration: 1400. Loss: 0.019712846726179123. Accuracy: 89.28571428571429%\n",
      "Iteration: 1500. Loss: 0.006958418060094118. Accuracy: 97.85714285714286%\n",
      "Iteration: 1600. Loss: 0.029960764572024345. Accuracy: 99.04761904761905%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Actually train the model with train data\n",
    "'''\n",
    "'''\n",
    "***Explain*** the Training Code Chunk in detail. Especially what is torch.max() doing here?\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "max_epochs = 3\n",
    "model = model.train()\n",
    "for epoch in tqdm_notebook(range(max_epochs)):\n",
    "    print(\"EPOCH -- {}\".format(epoch))\n",
    "    for i, (sent, label) in enumerate(training_loader):\n",
    "        optimizer.zero_grad()\n",
    "        sent = sent.squeeze(0)\n",
    "        if torch.cuda.is_available():\n",
    "          sent = sent.cuda()\n",
    "          label = label.cuda()\n",
    "        output = model.forward(sent)[0]\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        \n",
    "        loss = loss_function(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for sent, label in testing_loader:\n",
    "                sent = sent.squeeze(0)\n",
    "                if torch.cuda.is_available():\n",
    "                  sent = sent.cuda()\n",
    "                  label = label.cuda()\n",
    "                output = model.forward(sent)[0]\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += label.size(0)\n",
    "                correct += (predicted.cpu() == label.cpu()).sum()\n",
    "            accuracy = 100.00 * correct.numpy() / total\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}%'.format(i, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zswPnTBBh9to"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "AUJIKtiINAHb"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "***Explain*** what is the get_reply function doing?\n",
    "'''\n",
    "def get_reply(msg):\n",
    "  model.eval()\n",
    "  input_msg, _ = prepare_features(msg)\n",
    "  if torch.cuda.is_available():\n",
    "    input_msg = input_msg.cuda()\n",
    "  output = model(input_msg)[0]\n",
    "  _, pred_label = torch.max(output.data, 1)\n",
    "  prediction=list(label_to_ix.keys())[pred_label]\n",
    "  return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QTMIQUTWNmEp",
    "outputId": "0d885435-d5e3-4abc-c274-2f249401b0b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AddToPlaylist', 'BookRestaurant', 'GetWeather', 'PlayMusic', 'RateBook', 'SearchCreativeWork', 'SearchScreeningEvent'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_ix.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "UqEuS5a-NkGo",
    "outputId": "5b166c00-dc56-4b43-a23e-790ebef9e282"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PlayMusic'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Different text sentences pass to the model'''\n",
    "\n",
    "get_reply(\"play radiohead song\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "PoAquwkMO8mB",
    "outputId": "6ba03dcd-f4ae-4fa1-8ba2-c126f1066edf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GetWeather'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reply(\"it is rainy in Sao Paulo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "pBVApLSXimEa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PlayMusic'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reply(\"sun shinnes all day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "uu5LiiHOip6l"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SearchCreativeWork'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reply(\"low humidity, high altitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "lZjsxgEIO8g0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BookRestaurant'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reply(\"Book tacos for me tonight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "a0NOU4AuO8VA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BookRestaurant'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reply(\"Book a table for me tonight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "YLX3-pmy2khU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PlayMusic'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reply(\"I want BBQ tonight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SearchCreativeWork\n",
      "BookRestaurant\n",
      "GetWeather\n",
      "AddToPlaylist\n",
      "SearchCreativeWork\n"
     ]
    }
   ],
   "source": [
    "print(get_reply('Who wrote the book The Martian?'))\n",
    "print(get_reply('Book a me a table at Song Bird'))\n",
    "print(get_reply('What is the weather in Boston?'))\n",
    "print(get_reply('Add shine on you crazy diamond to my playlist'))\n",
    "print(get_reply('Is where the red fern grows a good book?'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Text_Classification_RoBERTa.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "262a34a2d7d54c05bdece96a627f5239": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "45ee40a7fb6342309758f174eca9beae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": " 67%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8fe4100312e14bb388c58722e8077176",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a66c8919baf3401e8b5cf43383de7487",
      "value": 2
     }
    },
    "8fe4100312e14bb388c58722e8077176": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95675c0005b84a53980b5592204476a3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a66c8919baf3401e8b5cf43383de7487": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cffaf4cc325449c6a7d4670acf3177cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_45ee40a7fb6342309758f174eca9beae",
       "IPY_MODEL_ef195bee3c7648c8ac9aa214cfb214e2"
      ],
      "layout": "IPY_MODEL_95675c0005b84a53980b5592204476a3"
     }
    },
    "ef195bee3c7648c8ac9aa214cfb214e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc008e0c33104fafbb90e6f335d55357",
      "placeholder": "​",
      "style": "IPY_MODEL_262a34a2d7d54c05bdece96a627f5239",
      "value": " 2/3 [07:18&lt;03:34, 214.77s/it]"
     }
    },
    "fc008e0c33104fafbb90e6f335d55357": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
